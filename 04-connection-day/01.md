# Lab 1: üóÑÔ∏è SQLite Integration

Connect your Go service to the local SQLite database! Use the existing Chinook database and implement production-ready database patterns.

## üéØ Objectives
- Connect to the existing Chinook SQLite database
- Design efficient schema for protobuf storage
- Implement connection pooling and health monitoring
- Build database migration system

## üõ†Ô∏è Tasks

### Step 1: Set Up SQLite Database
The Chinook SQLite database is already provided in your workshop resources:

```bash
# Check that the database exists
ls -la workshop/resources/chinook.db

# Test connection
sqlite3 workshop/resources/chinook.db ".tables"
# Should show: albums, artists, customers, employees, genres, invoice_items, invoices, media_types, playlists, playlist_track, tracks

# Explore the existing customer table
sqlite3 workshop/resources/chinook.db "PRAGMA table_info(customers);"
```

### Step 2: Extend Database Schema for Protobuf
Create `sql/migrations/001_extend_customers.sql`:

```sql
-- Add protobuf-specific columns to existing customers table
-- Note: We'll work with the existing Chinook customers table

-- Add new columns for protobuf storage  
ALTER TABLE customers ADD COLUMN status INTEGER DEFAULT 1;
ALTER TABLE customers ADD COLUMN data TEXT; -- JSON as TEXT in SQLite
ALTER TABLE customers ADD COLUMN created_at DATETIME DEFAULT CURRENT_TIMESTAMP;
ALTER TABLE customers ADD COLUMN updated_at DATETIME DEFAULT CURRENT_TIMESTAMP;
ALTER TABLE customers ADD COLUMN version INTEGER DEFAULT 1;

-- Create indexes for performance
CREATE INDEX IF NOT EXISTS idx_customers_email ON customers(email);
CREATE INDEX IF NOT EXISTS idx_customers_status ON customers(status);
CREATE INDEX IF NOT EXISTS idx_customers_phone ON customers(phone);
CREATE INDEX IF NOT EXISTS idx_customers_created_at ON customers(created_at);
CREATE INDEX IF NOT EXISTS idx_customers_updated_at ON customers(updated_at);

-- Customer events table for audit trail
CREATE TABLE IF NOT EXISTS customer_events (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    customer_id INTEGER NOT NULL REFERENCES customers(customerId) ON DELETE CASCADE,
    event_type TEXT NOT NULL,
    event_data TEXT NOT NULL, -- JSON as TEXT in SQLite
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    created_by TEXT NOT NULL DEFAULT 'system'
);

CREATE INDEX IF NOT EXISTS idx_customer_events_customer_id ON customer_events(customer_id);
CREATE INDEX IF NOT EXISTS idx_customer_events_type ON customer_events(event_type);
CREATE INDEX IF NOT EXISTS idx_customer_events_created_at ON customer_events(created_at);

-- SQLite trigger to update updated_at timestamp
CREATE TRIGGER IF NOT EXISTS update_customers_updated_at
    AFTER UPDATE ON customers
    FOR EACH ROW
BEGIN
    UPDATE customers 
    SET updated_at = CURRENT_TIMESTAMP,
        version = OLD.version + 1
    WHERE customerId = NEW.customerId;
END;

-- Initialize protobuf data for existing customers
UPDATE customers 
SET data = json_object(
    'addresses', json_array(),
    'preferences', json_object(
        'email_notifications', 1,
        'sms_notifications', 0
    )
)
WHERE data IS NULL;
```

### Step 3: Create Database Connection Layer
Create `internal/database/sqlite.go`:

```go
package database

import (
	"context"
	"database/sql"
	"fmt"
	"path/filepath"
	"strings"
	"time"

	_ "github.com/mattn/go-sqlite3" // SQLite driver
	"example.com/chinook/data-pipeline/internal/config"
	"example.com/chinook/data-pipeline/internal/domain"
)

// SQLiteDB wraps sql.DB with additional functionality
type SQLiteDB struct {
	db     *sql.DB
	config *config.DatabaseConfig
	logger domain.Logger
}

// NewSQLiteDB creates a new SQLite database connection
func NewSQLiteDB(cfg *config.DatabaseConfig, logger domain.Logger) (*SQLiteDB, error) {
	// Use the chinook.db file from workshop resources
	dbPath := filepath.Join("workshop", "resources", "chinook.db")
	dsn := fmt.Sprintf("file:%s?cache=shared&mode=rwc", dbPath)
	
	db, err := sql.Open("sqlite3", dsn)
	if err != nil {
		return nil, fmt.Errorf("failed to open database: %w", err)
	}

	// Configure connection pool for SQLite
	db.SetMaxOpenConns(1) // SQLite only allows one writer
	db.SetMaxIdleConns(1)
	db.SetConnMaxLifetime(cfg.ConnMaxLifetime)
	db.SetMaxIdleTime(cfg.MaxIdleTime)

	// Enable foreign keys and WAL mode for better concurrency
	if _, err := db.Exec("PRAGMA foreign_keys = ON; PRAGMA journal_mode = WAL;"); err != nil {
		db.Close()
		return nil, fmt.Errorf("failed to configure SQLite: %w", err)
	}

	sqliteDB := &SQLiteDB{
		db:     db,
		config: cfg,
		logger: logger,
	}

	// Test connection
	ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)
	defer cancel()

	if err := sqliteDB.Ping(ctx); err != nil {
		db.Close()
		return nil, fmt.Errorf("failed to ping database: %w", err)
	}

	logger.Info("database connection established",
		domain.Field{Key: "path", Value: dbPath},
		domain.Field{Key: "database", Value: "chinook"})

	return sqliteDB, nil
}

// DB returns the underlying sql.DB for direct access when needed
func (s *SQLiteDB) DB() *sql.DB {
	return s.db
}

// Ping tests the database connection
func (s *SQLiteDB) Ping(ctx context.Context) error {
	return s.db.PingContext(ctx)
}

// Close closes the database connection
func (s *SQLiteDB) Close() error {
	return s.db.Close()
}

// HealthCheck performs a comprehensive health check
func (s *SQLiteDB) HealthCheck(ctx context.Context) error {
	// Basic connectivity
	if err := s.Ping(ctx); err != nil {
		return fmt.Errorf("ping failed: %w", err)
	}

	// Test query execution
	var result int
	query := "SELECT 1"
	if err := s.db.QueryRowContext(ctx, query).Scan(&result); err != nil {
		return fmt.Errorf("test query failed: %w", err)
	}

	if result != 1 {
		return fmt.Errorf("test query returned unexpected result: %d", result)
	}

	// Check connection stats
	stats := s.db.Stats()
	s.logger.Debug("database connection stats",
		domain.Field{Key: "open_connections", Value: stats.OpenConnections},
		domain.Field{Key: "in_use", Value: stats.InUse},
		domain.Field{Key: "idle", Value: stats.Idle},
		domain.Field{Key: "wait_count", Value: stats.WaitCount},
		domain.Field{Key: "wait_duration", Value: stats.WaitDuration})

	// SQLite-specific checks
	var walMode string
	if err := s.db.QueryRowContext(ctx, "PRAGMA journal_mode").Scan(&walMode); err == nil {
		s.logger.Debug("SQLite configuration",
			domain.Field{Key: "journal_mode", Value: walMode})
	}

	return nil
}

// Stats returns database connection statistics
func (s *SQLiteDB) Stats() sql.DBStats {
	return s.db.Stats()
}

// Transaction executes a function within a database transaction
func (s *SQLiteDB) Transaction(ctx context.Context, fn func(*sql.Tx) error) error {
	tx, err := s.db.BeginTx(ctx, nil)
	if err != nil {
		return fmt.Errorf("failed to begin transaction: %w", err)
	}

	// Ensure transaction is rolled back if function panics
	defer func() {
		if r := recover(); r != nil {
			tx.Rollback()
			panic(r)
		}
	}()

	// Execute function
	if err := fn(tx); err != nil {
		if rollbackErr := tx.Rollback(); rollbackErr != nil {
			s.logger.Error("failed to rollback transaction",
				domain.Field{Key: "original_error", Value: err},
				domain.Field{Key: "rollback_error", Value: rollbackErr})
		}
		return err
	}

	// Commit transaction
	if err := tx.Commit(); err != nil {
		return fmt.Errorf("failed to commit transaction: %w", err)
	}

	return nil
}

// ReadOnlyTransaction executes a read-only transaction
func (s *SQLiteDB) ReadOnlyTransaction(ctx context.Context, fn func(*sql.Tx) error) error {
	tx, err := s.db.BeginTx(ctx, &sql.TxOptions{
		Isolation: sql.LevelReadCommitted,
		ReadOnly:  true,
	})
	if err != nil {
		return fmt.Errorf("failed to begin read-only transaction: %w", err)
	}

	defer func() {
		if r := recover(); r != nil {
			tx.Rollback()
			panic(r)
		}
	}()

	if err := fn(tx); err != nil {
		tx.Rollback()
		return err
	}

	return tx.Commit()
}

// Migrate runs database migrations
func (s *SQLiteDB) Migrate(ctx context.Context) error {
	// Simple migration system
	migrations := []struct {
		version int
		name    string
		sql     string
	}{
		{
			version: 1,
			name:    "add_protobuf_columns",
			sql: `
				ALTER TABLE customers ADD COLUMN status INTEGER DEFAULT 1;
				ALTER TABLE customers ADD COLUMN data TEXT;
				ALTER TABLE customers ADD COLUMN created_at DATETIME DEFAULT CURRENT_TIMESTAMP;
				ALTER TABLE customers ADD COLUMN updated_at DATETIME DEFAULT CURRENT_TIMESTAMP;
				ALTER TABLE customers ADD COLUMN version INTEGER DEFAULT 1;
			`,
		},
		{
			version: 2,
			name:    "create_indexes",
			sql: `
				CREATE INDEX IF NOT EXISTS idx_customers_email ON customers(email);
				CREATE INDEX IF NOT EXISTS idx_customers_status ON customers(status);
				CREATE INDEX IF NOT EXISTS idx_customers_phone ON customers(phone);
			`,
		},
		{
			version: 3,
			name:    "create_events_table",
			sql: `
				CREATE TABLE IF NOT EXISTS customer_events (
					id INTEGER PRIMARY KEY AUTOINCREMENT,
					customer_id INTEGER NOT NULL REFERENCES customers(customerId),
					event_type TEXT NOT NULL,
					event_data TEXT NOT NULL,
					created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
					created_by TEXT NOT NULL DEFAULT 'system'
				);
				CREATE INDEX IF NOT EXISTS idx_customer_events_customer_id ON customer_events(customer_id);
			`,
		},
	}

	// Create migrations table if it doesn't exist
	createMigrationsTable := `
		CREATE TABLE IF NOT EXISTS schema_migrations (
			version INTEGER PRIMARY KEY,
			name TEXT NOT NULL,
			applied_at DATETIME DEFAULT CURRENT_TIMESTAMP
		);
	`

	if _, err := s.db.ExecContext(ctx, createMigrationsTable); err != nil {
		return fmt.Errorf("failed to create migrations table: %w", err)
	}

	// Apply migrations
	for _, migration := range migrations {
		var count int
		checkQuery := "SELECT COUNT(*) FROM schema_migrations WHERE version = ?"
		if err := s.db.QueryRowContext(ctx, checkQuery, migration.version).Scan(&count); err != nil {
			return fmt.Errorf("failed to check migration status: %w", err)
		}

		if count > 0 {
			s.logger.Debug("migration already applied",
				domain.Field{Key: "version", Value: migration.version},
				domain.Field{Key: "name", Value: migration.name})
			continue
		}

		s.logger.Info("applying migration",
			domain.Field{Key: "version", Value: migration.version},
			domain.Field{Key: "name", Value: migration.name})

		err := s.Transaction(ctx, func(tx *sql.Tx) error {
			// Apply migration (handle ALTER TABLE statements separately)
			if migration.version == 1 {
				// Handle ALTER TABLE statements that might fail if columns exist
				statements := []string{
					"ALTER TABLE customers ADD COLUMN status INTEGER DEFAULT 1",
					"ALTER TABLE customers ADD COLUMN data TEXT",
					"ALTER TABLE customers ADD COLUMN created_at DATETIME DEFAULT CURRENT_TIMESTAMP",
					"ALTER TABLE customers ADD COLUMN updated_at DATETIME DEFAULT CURRENT_TIMESTAMP",
					"ALTER TABLE customers ADD COLUMN version INTEGER DEFAULT 1",
				}
				for _, stmt := range statements {
					if _, err := tx.ExecContext(ctx, stmt); err != nil {
						// Ignore "duplicate column" errors
						if !strings.Contains(err.Error(), "duplicate column") {
							return fmt.Errorf("failed to execute statement: %w", err)
						}
					}
				}
			} else {
				if _, err := tx.ExecContext(ctx, migration.sql); err != nil {
					return fmt.Errorf("failed to execute migration SQL: %w", err)
				}
			}

			// Record migration
			recordQuery := "INSERT INTO schema_migrations (version, name) VALUES (?, ?)"
			if _, err := tx.ExecContext(ctx, recordQuery, migration.version, migration.name); err != nil {
				return fmt.Errorf("failed to record migration: %w", err)
			}

			return nil
		})

		if err != nil {
			return fmt.Errorf("failed to apply migration %d: %w", migration.version, err)
		}

		s.logger.Info("migration applied successfully",
			domain.Field{Key: "version", Value: migration.version})
	}

	return nil
}

// Monitoring provides database monitoring capabilities
type Monitoring struct {
	db     *SQLiteDB
	logger domain.Logger
}

// NewMonitoring creates a new database monitoring instance
func NewMonitoring(db *SQLiteDB, logger domain.Logger) *Monitoring {
	return &Monitoring{
		db:     db,
		logger: logger,
	}
}

// StartMonitoring starts background monitoring of database health
func (m *Monitoring) StartMonitoring(ctx context.Context, interval time.Duration) {
	ticker := time.NewTicker(interval)
	defer ticker.Stop()

	for {
		select {
		case <-ctx.Done():
			return
		case <-ticker.C:
			m.checkHealth(ctx)
		}
	}
}

func (m *Monitoring) checkHealth(ctx context.Context) {
	if err := m.db.HealthCheck(ctx); err != nil {
		m.logger.Error("database health check failed",
			domain.Field{Key: "error", Value: err})
	}

	stats := m.db.Stats()
	
	// Log stats periodically
	m.logger.Debug("database monitoring stats",
		domain.Field{Key: "open_connections", Value: stats.OpenConnections},
		domain.Field{Key: "in_use", Value: stats.InUse},
		domain.Field{Key: "idle", Value: stats.Idle})

	// Alert on concerning metrics
	if stats.OpenConnections > 20 {
		m.logger.Warn("high number of open connections",
			domain.Field{Key: "open_connections", Value: stats.OpenConnections})
	}

	if stats.WaitDuration > time.Second {
		m.logger.Warn("high wait duration for connections",
			domain.Field{Key: "wait_duration", Value: stats.WaitDuration})
	}
}
```

### Step 4: Test Database Integration
Create `cmd/database-test/main.go`:

```go
package main

import (
	"context"
	"fmt"
	"log"
	"time"

	"example.com/chinook/data-pipeline/internal/config"
	"example.com/chinook/data-pipeline/internal/database"
	"example.com/chinook/data-pipeline/internal/domain"
	"example.com/chinook/data-pipeline/internal/mocks"
)

func main() {
	fmt.Println("üóÑÔ∏è SQLite Integration Laboratory")
	fmt.Println("=================================")

	testDatabaseConnection()
	testHealthChecks()
	testTransactions()
	testMonitoring()
}

func testDatabaseConnection() {
	fmt.Println("\nüîå Testing Database Connection")

	// Configure for local SQLite
	cfg := &config.DatabaseConfig{
		DatabasePath:    "workshop/resources/chinook.db",
		MaxConnections:  1, // SQLite only allows one writer
		MaxIdleTime:     15 * time.Minute,
		ConnMaxLifetime: 1 * time.Hour,
	}

	logger := mocks.NewMockLogger()

	// Test connection
	db, err := database.NewSQLiteDB(cfg, logger)
	if err != nil {
		fmt.Printf("‚ùå Failed to connect to database: %v\n", err)
		fmt.Println("   Make sure chinook.db exists in workshop/resources/")
		return
	}
	defer db.Close()

	fmt.Printf("‚úÖ Database connection established\n")

	// Test ping
	ctx := context.Background()
	if err := db.Ping(ctx); err != nil {
		fmt.Printf("‚ùå Database ping failed: %v\n", err)
		return
	}

	fmt.Printf("‚úÖ Database ping successful\n")

	// Run migrations
	if err := db.Migrate(ctx); err != nil {
		fmt.Printf("‚ùå Database migration failed: %v\n", err)
		return
	}

	fmt.Printf("‚úÖ Database migrations completed\n")

	// Test basic query - check existing customers
	var count int
	query := "SELECT COUNT(*) FROM customers"
	if err := db.DB().QueryRowContext(ctx, query).Scan(&count); err != nil {
		fmt.Printf("‚ùå Test query failed: %v\n", err)
		return
	}

	fmt.Printf("‚úÖ Found %d customers in Chinook database\n", count)

	// Show sample customer data
	var name, email string
	sampleQuery := "SELECT FirstName || ' ' || LastName, Email FROM customers LIMIT 1"
	if err := db.DB().QueryRowContext(ctx, sampleQuery).Scan(&name, &email); err != nil {
		fmt.Printf("‚ùå Sample query failed: %v\n", err)
		return
	}

	fmt.Printf("‚úÖ Sample customer: %s (%s)\n", name, email)
}

func testHealthChecks() {
	fmt.Println("\nüè• Testing Health Checks")

	cfg := &config.DatabaseConfig{
		DatabasePath:    "workshop/resources/chinook.db",
		MaxConnections:  1,
		MaxIdleTime:     15 * time.Minute,
		ConnMaxLifetime: 1 * time.Hour,
	}

	logger := mocks.NewMockLogger()

	db, err := database.NewSQLiteDB(cfg, logger)
	if err != nil {
		fmt.Printf("‚ùå Failed to connect: %v\n", err)
		return
	}
	defer db.Close()

	ctx := context.Background()

	// Test health check
	if err := db.HealthCheck(ctx); err != nil {
		fmt.Printf("‚ùå Health check failed: %v\n", err)
		return
	}

	fmt.Printf("‚úÖ Health check passed\n")

	// Show connection stats
	stats := db.Stats()
	fmt.Printf("   Connection stats:\n")
	fmt.Printf("   - Open connections: %d\n", stats.OpenConnections)
	fmt.Printf("   - In use: %d\n", stats.InUse)
	fmt.Printf("   - Idle: %d\n", stats.Idle)
	fmt.Printf("   - Wait count: %d\n", stats.WaitCount)
	fmt.Printf("   - Wait duration: %v\n", stats.WaitDuration)
}

func testTransactions() {
	fmt.Println("\nüí≥ Testing Transactions")

	cfg := &config.DatabaseConfig{
		DatabasePath: "workshop/resources/chinook.db",
	}

	logger := mocks.NewMockLogger()

	db, err := database.NewSQLiteDB(cfg, logger)
	if err != nil {
		fmt.Printf("‚ùå Failed to connect: %v\n", err)
		return
	}
	defer db.Close()

	ctx := context.Background()

	// Test successful transaction
	fmt.Println("   Testing successful transaction...")
	err = db.Transaction(ctx, func(tx *sql.Tx) error {
		// Insert test customer event
		query := `
			INSERT INTO customer_events (customer_id, event_type, event_data, created_by) 
			VALUES (?, ?, ?, ?) 
		`
		result, err := tx.ExecContext(ctx, query, 
			1, // Use existing customer
			"test_transaction", 
			`{"test": true}`,
			"test_user")
		
		if err != nil {
			return err
		}

		id, _ := result.LastInsertId()
		fmt.Printf("   ‚úÖ Inserted event with ID: %d\n", id)
		return nil
	})

	if err != nil {
		fmt.Printf("   ‚ùå Transaction failed: %v\n", err)
	} else {
		fmt.Printf("   ‚úÖ Transaction completed successfully\n")
	}

	// Test transaction rollback
	fmt.Println("   Testing transaction rollback...")
	err = db.Transaction(ctx, func(tx *sql.Tx) error {
		// Insert customer event
		query := `
			INSERT INTO customer_events (customer_id, event_type, event_data, created_by) 
			VALUES (?, ?, ?, ?)
		`
		_, err := tx.ExecContext(ctx, query, 
			1,
			"rollback_test", 
			`{"test": true}`,
			"test_user")
		
		if err != nil {
			return err
		}

		// Force rollback by returning error
		return fmt.Errorf("intentional rollback")
	})

	if err != nil {
		fmt.Printf("   ‚úÖ Transaction rolled back as expected: %v\n", err)
	} else {
		fmt.Printf("   ‚ùå Transaction should have rolled back\n")
	}

	// Verify rollback worked
	var count int
	query := "SELECT COUNT(*) FROM customer_events WHERE event_type = ?"
	db.DB().QueryRowContext(ctx, query, "rollback_test").Scan(&count)
	if count == 0 {
		fmt.Printf("   ‚úÖ Rollback verified - event not found\n")
	} else {
		fmt.Printf("   ‚ùå Rollback failed - event found\n")
	}
}

func testMonitoring() {
	fmt.Println("\nüìä Testing Database Monitoring")

	cfg := &config.DatabaseConfig{
		DatabasePath: "workshop/resources/chinook.db",
	}

	logger := mocks.NewMockLogger()

	db, err := database.NewSQLiteDB(cfg, logger)
	if err != nil {
		fmt.Printf("‚ùå Failed to connect: %v\n", err)
		return
	}
	defer db.Close()

	// Create monitoring
	monitoring := database.NewMonitoring(db, logger)

	// Start monitoring in background
	ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
	defer cancel()

	fmt.Printf("   Starting monitoring for 5 seconds...\n")
	
	// Run monitoring in background
	go monitoring.StartMonitoring(ctx, 1*time.Second)

	// Simulate some database activity
	for i := 0; i < 3; i++ {
		time.Sleep(1 * time.Second)
		db.HealthCheck(ctx)
		fmt.Printf("   ‚úÖ Health check %d completed\n", i+1)
	}

	// Wait for monitoring to finish
	<-ctx.Done()
	fmt.Printf("   ‚úÖ Monitoring completed\n")

	// Show final stats
	stats := db.Stats()
	fmt.Printf("   Final connection stats:\n")
	fmt.Printf("   - Max open connections: %d\n", stats.MaxOpenConnections)
	fmt.Printf("   - Open connections: %d\n", stats.OpenConnections)
	fmt.Printf("   - In use: %d\n", stats.InUse)
	fmt.Printf("   - Idle: %d\n", stats.Idle)

	fmt.Println("\nüéâ SQLite integration testing completed!")
}
```

## ‚úÖ Victory Conditions

- [ ] SQLite connection established to chinook.db
- [ ] Database schema extended to support protobuf storage
- [ ] Connection pooling configured for SQLite
- [ ] Health checks and monitoring work
- [ ] Transactions handle success and rollback scenarios
- [ ] Can query existing Chinook customer data

## üìö What You Learned

- How to work with existing SQLite databases
- Extending schemas with migrations
- SQLite-specific considerations (WAL mode, single writer)
- Integrating protobuf data with relational storage

---

**Next**: Head to `lab02/` to implement the repository pattern! üîÑ