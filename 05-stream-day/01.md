# Lab 1: üì° Bufstream Setup & Basics

Set up your streaming infrastructure! Install Bufstream, create your first topics, and build producer/consumer applications.

## üéØ Objectives
- Install and configure Bufstream locally
- Create topics with protobuf schemas
- Build reliable producer/consumer patterns
- Implement error handling and retries

## üõ†Ô∏è Tasks

### Step 1: Install Bufstream
```bash
# Install Bufstream CLI
curl -sSL https://install.bufstream.dev | sh

# Verify installation
bufstream version

# Start Bufstream server locally
bufstream server start --config-file bufstream.yaml
```

Create `bufstream.yaml`:
```yaml
server:
  bind_address: "0.0.0.0:9092"
  
storage:
  type: "local"
  path: "./bufstream-data"

schema_registry:
  enabled: true
  port: 8080

topics:
  customer_events:
    partitions: 3
    replication_factor: 1
    schema: "customer.v1.CustomerEvent"
  
  customer_commands:
    partitions: 1
    replication_factor: 1  
    schema: "customer.v1.CustomerCommand"

logging:
  level: "info"
```

### Step 2: Create Streaming Schemas
Create `api/events/v1/customer_events.proto`:

```protobuf
syntax = "proto3";

package events.v1;

option go_package = "github.com/chinook/data-pipeline/pkg/proto/events/v1;eventsv1";

import "google/protobuf/timestamp.proto";
import "customer/v1/customer.proto";

// Customer event types
enum CustomerEventType {
  CUSTOMER_EVENT_TYPE_UNSPECIFIED = 0;
  CUSTOMER_EVENT_TYPE_CREATED = 1;
  CUSTOMER_EVENT_TYPE_UPDATED = 2;
  CUSTOMER_EVENT_TYPE_DELETED = 3;
  CUSTOMER_EVENT_TYPE_STATUS_CHANGED = 4;
  CUSTOMER_EVENT_TYPE_CONTACT_UPDATED = 5;
}

// Main customer event message
message CustomerEvent {
  // Event metadata
  string event_id = 1;
  CustomerEventType event_type = 2;
  google.protobuf.Timestamp timestamp = 3;
  int64 version = 4;
  string correlation_id = 5;
  string causation_id = 6;
  
  // Event source
  string aggregate_id = 7;  // Customer ID
  string aggregate_type = 8; // "customer"
  
  // Event data
  oneof event_data {
    CustomerCreatedEvent customer_created = 10;
    CustomerUpdatedEvent customer_updated = 11;
    CustomerDeletedEvent customer_deleted = 12;
    CustomerStatusChangedEvent status_changed = 13;
    CustomerContactUpdatedEvent contact_updated = 14;
  }
  
  // Metadata
  map<string, string> metadata = 20;
}

// Specific event types
message CustomerCreatedEvent {
  customer.v1.Customer customer = 1;
  string created_by = 2;
  string source = 3; // "web", "api", "import", etc.
}

message CustomerUpdatedEvent {
  customer.v1.Customer customer = 1;
  customer.v1.Customer previous_customer = 2;
  string updated_by = 3;
  repeated string changed_fields = 4;
}

message CustomerDeletedEvent {
  int64 customer_id = 1;
  string deleted_by = 2;
  string reason = 3;
}

message CustomerStatusChangedEvent {
  int64 customer_id = 1;
  customer.v1.CustomerStatus old_status = 2;
  customer.v1.CustomerStatus new_status = 3;
  string changed_by = 4;
  string reason = 5;
}

message CustomerContactUpdatedEvent {
  int64 customer_id = 1;
  customer.v1.ContactInfo contact_info = 2;
  string updated_by = 3;
}

// Command messages (for CQRS pattern)
message CustomerCommand {
  string command_id = 1;
  google.protobuf.Timestamp timestamp = 2;
  string correlation_id = 3;
  
  oneof command_data {
    CreateCustomerCommand create_customer = 10;
    UpdateCustomerCommand update_customer = 11;
    DeleteCustomerCommand delete_customer = 12;
  }
  
  map<string, string> metadata = 20;
}

message CreateCustomerCommand {
  customer.v1.Customer customer = 1;
  string created_by = 2;
}

message UpdateCustomerCommand {
  customer.v1.Customer customer = 1;
  string updated_by = 2;
  repeated string fields_to_update = 3;
}

message DeleteCustomerCommand {
  int64 customer_id = 1;
  string deleted_by = 2;
  string reason = 3;
}
```

### Step 3: Build Event Producer
Create `internal/streaming/producer.go`:

```go
package streaming

import (
	"context"
	"fmt"
	"time"

	"github.com/bufbuild/bufstream-go"
	eventsv1 "github.com/chinook/data-pipeline/pkg/proto/events/v1"
	"github.com/chinook/data-pipeline/internal/domain"
	"google.golang.org/protobuf/proto"
	"google.golang.org/protobuf/types/known/timestamppb"
)

// EventProducer handles publishing events to Bufstream
type EventProducer struct {
	client  *bufstream.Client
	logger  domain.Logger
	metrics domain.Metrics
}

// NewEventProducer creates a new event producer
func NewEventProducer(client *bufstream.Client, logger domain.Logger, metrics domain.Metrics) *EventProducer {
	return &EventProducer{
		client:  client,
		logger:  logger,
		metrics: metrics,
	}
}

// PublishCustomerEvent publishes a customer event
func (p *EventProducer) PublishCustomerEvent(ctx context.Context, event *eventsv1.CustomerEvent) error {
	// Set event metadata
	if event.EventId == "" {
		event.EventId = generateEventID()
	}
	if event.Timestamp == nil {
		event.Timestamp = timestamppb.Now()
	}
	if event.AggregateType == "" {
		event.AggregateType = "customer"
	}

	// Serialize event
	data, err := proto.Marshal(event)
	if err != nil {
		p.metrics.Counter("event_serialize_errors").Inc()
		return fmt.Errorf("failed to marshal event: %w", err)
	}

	// Create Bufstream message
	message := &bufstream.Message{
		Topic:     "customer_events",
		Key:       []byte(event.AggregateId),
		Value:     data,
		Headers:   p.createHeaders(event),
		Timestamp: event.Timestamp.AsTime(),
	}

	// Publish with retry
	err = p.publishWithRetry(ctx, message, 3)
	if err != nil {
		p.logger.Error("failed to publish event",
			domain.Field{Key: "event_id", Value: event.EventId},
			domain.Field{Key: "event_type", Value: event.EventType.String()},
			domain.Field{Key: "error", Value: err})
		p.metrics.Counter("event_publish_errors").Inc()
		return fmt.Errorf("failed to publish event: %w", err)
	}

	p.logger.Info("event published successfully",
		domain.Field{Key: "event_id", Value: event.EventId},
		domain.Field{Key: "event_type", Value: event.EventType.String()},
		domain.Field{Key: "aggregate_id", Value: event.AggregateId})
	
	p.metrics.Counter("events_published").Inc()
	return nil
}

// PublishCustomerCreated publishes a customer created event
func (p *EventProducer) PublishCustomerCreated(ctx context.Context, customer *domain.Customer, createdBy string) error {
	event := &eventsv1.CustomerEvent{
		EventType:   eventsv1.CustomerEventType_CUSTOMER_EVENT_TYPE_CREATED,
		AggregateId: fmt.Sprintf("%d", customer.ID),
		Version:     1,
		EventData: &eventsv1.CustomerEvent_CustomerCreated{
			CustomerCreated: &eventsv1.CustomerCreatedEvent{
				Customer:  convertDomainToProto(customer),
				CreatedBy: createdBy,
				Source:    "api",
			},
		},
	}

	return p.PublishCustomerEvent(ctx, event)
}

// PublishCustomerUpdated publishes a customer updated event
func (p *EventProducer) PublishCustomerUpdated(ctx context.Context, customer *domain.Customer, previous *domain.Customer, updatedBy string, changedFields []string) error {
	event := &eventsv1.CustomerEvent{
		EventType:   eventsv1.CustomerEventType_CUSTOMER_EVENT_TYPE_UPDATED,
		AggregateId: fmt.Sprintf("%d", customer.ID),
		Version:     2, // Increment version
		EventData: &eventsv1.CustomerEvent_CustomerUpdated{
			CustomerUpdated: &eventsv1.CustomerUpdatedEvent{
				Customer:         convertDomainToProto(customer),
				PreviousCustomer: convertDomainToProto(previous),
				UpdatedBy:        updatedBy,
				ChangedFields:    changedFields,
			},
		},
	}

	return p.PublishCustomerEvent(ctx, event)
}

// publishWithRetry implements retry logic for publishing
func (p *EventProducer) publishWithRetry(ctx context.Context, message *bufstream.Message, maxRetries int) error {
	var lastErr error

	for attempt := 0; attempt < maxRetries; attempt++ {
		// Create context with timeout for this attempt
		attemptCtx, cancel := context.WithTimeout(ctx, 30*time.Second)
		
		err := p.client.Publish(attemptCtx, message)
		cancel()

		if err == nil {
			if attempt > 0 {
				p.logger.Info("publish succeeded after retry",
					domain.Field{Key: "attempt", Value: attempt + 1})
			}
			return nil
		}

		lastErr = err
		
		// Check if error is retryable
		if !isRetryableError(err) {
			return err
		}

		// Exponential backoff
		backoff := time.Duration(attempt+1) * 100 * time.Millisecond
		p.logger.Warn("publish attempt failed, retrying",
			domain.Field{Key: "attempt", Value: attempt + 1},
			domain.Field{Key: "error", Value: err},
			domain.Field{Key: "backoff", Value: backoff})

		select {
		case <-ctx.Done():
			return ctx.Err()
		case <-time.After(backoff):
			// Continue to next attempt
		}
	}

	return fmt.Errorf("max retries exceeded: %w", lastErr)
}

// createHeaders creates message headers
func (p *EventProducer) createHeaders(event *eventsv1.CustomerEvent) map[string][]byte {
	headers := make(map[string][]byte)
	headers["event-type"] = []byte(event.EventType.String())
	headers["aggregate-type"] = []byte(event.AggregateType)
	headers["event-version"] = []byte(fmt.Sprintf("%d", event.Version))
	
	if event.CorrelationId != "" {
		headers["correlation-id"] = []byte(event.CorrelationId)
	}
	
	return headers
}

// Helper functions
func generateEventID() string {
	return fmt.Sprintf("evt_%d_%d", time.Now().Unix(), time.Now().Nanosecond())
}

func isRetryableError(err error) bool {
	// Implement logic to determine if error is retryable
	// For now, retry all errors except context cancellation
	return err != context.Canceled && err != context.DeadlineExceeded
}

func convertDomainToProto(customer *domain.Customer) *customerv1.Customer {
	// Convert domain.Customer to protobuf Customer
	// This is a simplified conversion
	return &customerv1.Customer{
		Id:    customer.ID,
		Name:  customer.Name,
		Email: customer.Email,
	}
}
```

### Step 4: Build Event Consumer
Create `internal/streaming/consumer.go`:

```go
package streaming

import (
	"context"
	"fmt"
	"time"

	"github.com/bufbuild/bufstream-go"
	eventsv1 "github.com/chinook/data-pipeline/pkg/proto/events/v1"
	"github.com/chinook/data-pipeline/internal/domain"
	"google.golang.org/protobuf/proto"
)

// EventHandler defines the interface for handling events
type EventHandler interface {
	HandleCustomerCreated(ctx context.Context, event *eventsv1.CustomerCreatedEvent) error
	HandleCustomerUpdated(ctx context.Context, event *eventsv1.CustomerUpdatedEvent) error
	HandleCustomerDeleted(ctx context.Context, event *eventsv1.CustomerDeletedEvent) error
}

// EventConsumer handles consuming events from Bufstream
type EventConsumer struct {
	client   *bufstream.Client
	handler  EventHandler
	logger   domain.Logger
	metrics  domain.Metrics
	groupID  string
}

// NewEventConsumer creates a new event consumer
func NewEventConsumer(client *bufstream.Client, handler EventHandler, groupID string, logger domain.Logger, metrics domain.Metrics) *EventConsumer {
	return &EventConsumer{
		client:  client,
		handler: handler,
		logger:  logger,
		metrics: metrics,
		groupID: groupID,
	}
}

// Start starts consuming events
func (c *EventConsumer) Start(ctx context.Context) error {
	c.logger.Info("starting event consumer", domain.Field{Key: "group_id", Value: c.groupID})

	// Create consumer group
	consumer, err := c.client.NewConsumer(bufstream.ConsumerConfig{
		GroupID: c.groupID,
		Topics:  []string{"customer_events"},
		AutoOffsetReset: "earliest",
	})
	if err != nil {
		return fmt.Errorf("failed to create consumer: %w", err)
	}

	// Start consuming messages
	for {
		select {
		case <-ctx.Done():
			c.logger.Info("stopping event consumer")
			return consumer.Close()
		default:
			message, err := consumer.Poll(ctx, 5*time.Second)
			if err != nil {
				if err == context.DeadlineExceeded {
					continue // Timeout is expected
				}
				c.logger.Error("failed to poll message", domain.Field{Key: "error", Value: err})
				c.metrics.Counter("consumer_poll_errors").Inc()
				continue
			}

			if message == nil {
				continue // No message available
			}

			if err := c.processMessage(ctx, message); err != nil {
				c.logger.Error("failed to process message",
					domain.Field{Key: "topic", Value: message.Topic},
					domain.Field{Key: "partition", Value: message.Partition},
					domain.Field{Key: "offset", Value: message.Offset},
					domain.Field{Key: "error", Value: err})
				c.metrics.Counter("message_processing_errors").Inc()
				
				// Don't commit offset on error - message will be retried
				continue
			}

			// Commit offset after successful processing
			if err := consumer.Commit(ctx, message); err != nil {
				c.logger.Error("failed to commit offset",
					domain.Field{Key: "error", Value: err})
			}
		}
	}
}

// processMessage processes a single message
func (c *EventConsumer) processMessage(ctx context.Context, message *bufstream.Message) error {
	c.metrics.Counter("messages_received").Inc()

	// Deserialize event
	var event eventsv1.CustomerEvent
	if err := proto.Unmarshal(message.Value, &event); err != nil {
		return fmt.Errorf("failed to unmarshal event: %w", err)
	}

	c.logger.Info("processing event",
		domain.Field{Key: "event_id", Value: event.EventId},
		domain.Field{Key: "event_type", Value: event.EventType.String()},
		domain.Field{Key: "aggregate_id", Value: event.AggregateId})

	// Route event to appropriate handler
	switch eventData := event.EventData.(type) {
	case *eventsv1.CustomerEvent_CustomerCreated:
		return c.handler.HandleCustomerCreated(ctx, eventData.CustomerCreated)
	
	case *eventsv1.CustomerEvent_CustomerUpdated:
		return c.handler.HandleCustomerUpdated(ctx, eventData.CustomerUpdated)
	
	case *eventsv1.CustomerEvent_CustomerDeleted:
		return c.handler.HandleCustomerDeleted(ctx, eventData.CustomerDeleted)
	
	default:
		c.logger.Warn("unknown event type", 
			domain.Field{Key: "event_type", Value: event.EventType.String()})
		return nil // Don't fail on unknown events
	}
}

// CustomerEventHandler implements EventHandler for customer events
type CustomerEventHandler struct {
	logger domain.Logger
}

// NewCustomerEventHandler creates a new customer event handler
func NewCustomerEventHandler(logger domain.Logger) *CustomerEventHandler {
	return &CustomerEventHandler{
		logger: logger,
	}
}

// HandleCustomerCreated handles customer created events
func (h *CustomerEventHandler) HandleCustomerCreated(ctx context.Context, event *eventsv1.CustomerCreatedEvent) error {
	h.logger.Info("handling customer created event",
		domain.Field{Key: "customer_id", Value: event.Customer.Id},
		domain.Field{Key: "customer_name", Value: event.Customer.Name},
		domain.Field{Key: "created_by", Value: event.CreatedBy})

	// Process the event - could be:
	// - Update read models
	// - Send welcome email
	// - Create billing account
	// - etc.

	// Simulate processing time
	time.Sleep(100 * time.Millisecond)

	return nil
}

// HandleCustomerUpdated handles customer updated events
func (h *CustomerEventHandler) HandleCustomerUpdated(ctx context.Context, event *eventsv1.CustomerUpdatedEvent) error {
	h.logger.Info("handling customer updated event",
		domain.Field{Key: "customer_id", Value: event.Customer.Id},
		domain.Field{Key: "updated_by", Value: event.UpdatedBy},
		domain.Field{Key: "changed_fields", Value: event.ChangedFields})

	// Process the update
	time.Sleep(50 * time.Millisecond)

	return nil
}

// HandleCustomerDeleted handles customer deleted events
func (h *CustomerEventHandler) HandleCustomerDeleted(ctx context.Context, event *eventsv1.CustomerDeletedEvent) error {
	h.logger.Info("handling customer deleted event",
		domain.Field{Key: "customer_id", Value: event.CustomerId},
		domain.Field{Key: "deleted_by", Value: event.DeletedBy},
		domain.Field{Key: "reason", Value: event.Reason})

	// Process the deletion
	time.Sleep(200 * time.Millisecond)

	return nil
}
```

### Step 5: Test Streaming Implementation
Create `cmd/streaming-test/main.go`:

```go
package main

import (
	"context"
	"fmt"
	"log"
	"sync"
	"time"

	"github.com/bufbuild/bufstream-go"
	"github.com/chinook/data-pipeline/internal/domain"
	"github.com/chinook/data-pipeline/internal/mocks"
	"github.com/chinook/data-pipeline/internal/streaming"
)

func main() {
	fmt.Println("üì° Bufstream Integration Laboratory")
	fmt.Println("==================================")

	testBasicProducerConsumer()
	testEventPublishing()
	testEventHandling()
	testErrorRecovery()
}

func testBasicProducerConsumer() {
	fmt.Println("\nüîÑ Testing Basic Producer/Consumer")

	// Create Bufstream client
	client, err := bufstream.NewClient(bufstream.Config{
		Brokers: []string{"localhost:9092"},
	})
	if err != nil {
		fmt.Printf("‚ùå Failed to create Bufstream client: %v\n", err)
		fmt.Println("   Make sure Bufstream is running with: bufstream server start")
		return
	}
	defer client.Close()

	logger := mocks.NewMockLogger()
	metrics := mocks.NewMockMetrics()

	// Create producer
	producer := streaming.NewEventProducer(client, logger, metrics)

	// Create dummy customer
	customer := &domain.Customer{
		ID:    1,
		Name:  "Streaming Test Customer",
		Email: "streaming@test.com",
	}

	// Publish customer created event
	ctx := context.Background()
	if err := producer.PublishCustomerCreated(ctx, customer, "test-system"); err != nil {
		fmt.Printf("‚ùå Failed to publish event: %v\n", err)
		return
	}

	fmt.Printf("‚úÖ Event published successfully\n")
	
	// Test consumer
	handler := streaming.NewCustomerEventHandler(logger)
	consumer := streaming.NewEventConsumer(client, handler, "test-group", logger, metrics)

	// Start consumer in background
	ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)
	defer cancel()

	go func() {
		if err := consumer.Start(ctx); err != nil {
			fmt.Printf("Consumer error: %v\n", err)
		}
	}()

	// Wait for processing
	time.Sleep(5 * time.Second)
	fmt.Printf("‚úÖ Consumer processed events\n")
}

func testEventPublishing() {
	fmt.Println("\nüì¢ Testing Event Publishing Patterns")

	client, err := bufstream.NewClient(bufstream.Config{
		Brokers: []string{"localhost:9092"},
	})
	if err != nil {
		fmt.Printf("‚ùå Failed to create client: %v\n", err)
		return
	}
	defer client.Close()

	logger := mocks.NewMockLogger()
	metrics := mocks.NewMockMetrics()
	producer := streaming.NewEventProducer(client, logger, metrics)

	ctx := context.Background()

	// Test different event types
	customers := []*domain.Customer{
		{ID: 1, Name: "Event Test 1", Email: "event1@test.com"},
		{ID: 2, Name: "Event Test 2", Email: "event2@test.com"},
		{ID: 3, Name: "Event Test 3", Email: "event3@test.com"},
	}

	fmt.Printf("   Publishing %d customer created events...\n", len(customers))
	for _, customer := range customers {
		if err := producer.PublishCustomerCreated(ctx, customer, "batch-test"); err != nil {
			fmt.Printf("   ‚ùå Failed to publish event for customer %d: %v\n", customer.ID, err)
		} else {
			fmt.Printf("   ‚úÖ Published event for customer %d\n", customer.ID)
		}
		time.Sleep(100 * time.Millisecond) // Small delay between events
	}

	// Test update event
	updatedCustomer := customers[0]
	updatedCustomer.Name = "Updated Event Test 1"
	
	if err := producer.PublishCustomerUpdated(ctx, updatedCustomer, customers[0], "test-updater", []string{"name"}); err != nil {
		fmt.Printf("   ‚ùå Failed to publish update event: %v\n", err)
	} else {
		fmt.Printf("   ‚úÖ Published customer updated event\n")
	}
}

func testEventHandling() {
	fmt.Println("\nüéØ Testing Event Handling")

	client, err := bufstream.NewClient(bufstream.Config{
		Brokers: []string{"localhost:9092"},
	})
	if err != nil {
		fmt.Printf("‚ùå Failed to create client: %v\n", err)
		return
	}
	defer client.Close()

	logger := mocks.NewMockLogger()
	metrics := mocks.NewMockMetrics()

	// Create multiple consumers to test parallel processing
	const numConsumers = 3
	var wg sync.WaitGroup

	ctx, cancel := context.WithTimeout(context.Background(), 15*time.Second)
	defer cancel()

	for i := 0; i < numConsumers; i++ {
		wg.Add(1)
		go func(consumerID int) {
			defer wg.Done()

			handler := streaming.NewCustomerEventHandler(logger)
			consumer := streaming.NewEventConsumer(
				client, 
				handler, 
				fmt.Sprintf("test-group-%d", consumerID), 
				logger, 
				metrics,
			)

			fmt.Printf("   Starting consumer %d\n", consumerID)
			if err := consumer.Start(ctx); err != nil && err != context.DeadlineExceeded {
				fmt.Printf("   ‚ùå Consumer %d error: %v\n", consumerID, err)
			} else {
				fmt.Printf("   ‚úÖ Consumer %d completed\n", consumerID)
			}
		}(i)
	}

	// Wait for consumers to process events
	wg.Wait()
	fmt.Printf("   ‚úÖ All consumers completed\n")
}

func testErrorRecovery() {
	fmt.Println("\nüîÑ Testing Error Recovery")

	client, err := bufstream.NewClient(bufstream.Config{
		Brokers: []string{"localhost:9092"},
	})
	if err != nil {
		fmt.Printf("‚ùå Failed to create client: %v\n", err)
		return
	}
	defer client.Close()

	logger := mocks.NewMockLogger()
	metrics := mocks.NewMockMetrics()
	producer := streaming.NewEventProducer(client, logger, metrics)

	ctx := context.Background()

	// Test publishing with network issues (simulated)
	customer := &domain.Customer{
		ID:    999,
		Name:  "Error Recovery Test",
		Email: "error@test.com",
	}

	// This should succeed with retries
	fmt.Printf("   Testing publish with retry logic...\n")
	if err := producer.PublishCustomerCreated(ctx, customer, "error-test"); err != nil {
		fmt.Printf("   ‚ùå Publish failed even with retries: %v\n", err)
	} else {
		fmt.Printf("   ‚úÖ Publish succeeded (possibly after retries)\n")
	}

	fmt.Println("\nüéâ Streaming integration testing completed!")
	fmt.Println("\nüí° Key Concepts Demonstrated:")
	fmt.Println("   ‚úÖ Event-driven architecture with Bufstream")
	fmt.Println("   ‚úÖ Schema-aware message serialization") 
	fmt.Println("   ‚úÖ Producer retry logic and error handling")
	fmt.Println("   ‚úÖ Consumer group parallel processing")
	fmt.Println("   ‚úÖ Event routing and handler patterns")
}
```

## üí• Deliberate Failure: Stream Resilience

### Break It:
1. Stop Bufstream server while publishing events
2. Send malformed protobuf messages
3. Create consumer that throws exceptions

### Fix It:
The producer should retry failed publishes, and consumers should handle bad messages gracefully.

## ‚úÖ Victory Conditions

- [ ] Bufstream runs locally and accepts connections
- [ ] Events publish successfully with schema validation
- [ ] Consumers process events in parallel
- [ ] Error handling and retries work correctly
- [ ] Event routing handles different message types

---

**Next**: Head to `lab02/` for event-driven architecture patterns! üîÑ